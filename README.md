# ğŸš€ Prompt Router

Sistema inteligente de otimizaÃ§Ã£o e roteamento de prompts para mÃºltiplos LLMs (Claude, OpenAI, Cursor).

## ğŸ“‹ VisÃ£o Geral

O **Prompt Router** Ã© uma ferramenta desenvolvida para otimizar e rotear prompts automaticamente para diferentes Large Language Models (LLMs), aplicando as melhores prÃ¡ticas especÃ­ficas de cada modelo e formatando adequadamente para mÃ¡xima eficiÃªncia.

### ğŸ¯ Funcionalidades Principais

- **OtimizaÃ§Ã£o Inteligente**: Aplica otimizaÃ§Ãµes especÃ­ficas baseadas no LLM de destino
- **Roteamento AutomÃ¡tico**: Determina automaticamente o melhor LLM para cada tipo de prompt
- **Templates Personalizados**: Usa templates otimizados para Claude, OpenAI e Cursor
- **Multi-Output**: Suporte para mÃºltiplos formatos de saÃ­da
- **ExtensÃ­vel**: Arquitetura modular para fÃ¡cil expansÃ£o

## ğŸ—ï¸ Estrutura do Projeto

```
PromptRouter/
â”œâ”€â”€ main.py                 # Ponto de entrada principal
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â”œâ”€â”€ .env                   # ConfiguraÃ§Ãµes de ambiente
â”œâ”€â”€ README.md              # DocumentaÃ§Ã£o (este arquivo)
â”‚
â”œâ”€â”€ config/                # ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py        # Classe Settings com todas as configuraÃ§Ãµes
â”‚
â”œâ”€â”€ chains/                # MÃ³dulos principais de processamento
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ prompt_optimizer.py    # Otimizador de prompts
â”‚   â”œâ”€â”€ llm_router.py         # Roteador de LLMs
â”‚   â””â”€â”€ api_client.py         # Cliente de APIs (placeholder)
â”‚
â”œâ”€â”€ templates/             # Templates para diferentes LLMs
â”‚   â”œâ”€â”€ claude_template.txt    # Template otimizado para Claude
â”‚   â”œâ”€â”€ openai_template.txt    # Template otimizado para OpenAI
â”‚   â”œâ”€â”€ cursor_template.txt    # Template otimizado para Cursor
â”‚   â””â”€â”€ universal_template.txt # Template universal
â”‚
â”œâ”€â”€ utils/                 # UtilitÃ¡rios e ferramentas auxiliares
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ logger.py          # Sistema de logging
â”‚
â””â”€â”€ logs/                  # Arquivos de log (gerado automaticamente)
```

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### 2. InstalaÃ§Ã£o de DependÃªncias

```bash
# Clone ou baixe o projeto
cd PromptRouter

# Instale as dependÃªncias
pip install -r requirements.txt
```

### 3. ConfiguraÃ§Ã£o do Ambiente

1. Copie o arquivo `.env` e configure suas chaves de API:

```bash
# Edite o arquivo .env e configure suas chaves
ANTHROPIC_API_KEY=sua_chave_anthropic_aqui
OPENAI_API_KEY=sua_chave_openai_aqui
CURSOR_API_KEY=sua_chave_cursor_aqui
```

2. Pelo menos uma chave de API deve ser configurada para usar o sistema.

## ğŸ’» Como Usar

### Uso BÃ¡sico via Linha de Comando

```bash
# Exemplo bÃ¡sico - prompt simples
python main.py --input "Explique o conceito de machine learning"

# Otimizar prompt para Claude especificamente
python main.py --input "Analise os prÃ³s e contras da IA" --target claude --optimize

# Roteamento automÃ¡tico com otimizaÃ§Ã£o
python main.py --input "Crie uma funÃ§Ã£o Python para calcular fibonacci" --optimize

# Usar template especÃ­fico para OpenAI
python main.py --input "Escreva um texto criativo sobre o futuro" --target openai --optimize
```

### OpÃ§Ãµes de Linha de Comando

- `--input, -i`: Prompt de entrada (obrigatÃ³rio)
- `--target, -t`: LLM de destino (`claude`, `openai`, `cursor`, `universal`)
- `--optimize, -o`: Aplica otimizaÃ§Ã£o ao prompt
- `--send, -s`: Envio direto para LLM (funcionalidade futura)

### Exemplos de SaÃ­da

```
ğŸš€ Iniciando Prompt Router v1.0.0
ğŸ“ Prompt de entrada: Explique machine learning de forma simples...
ğŸ¯ Destino: claude
ğŸ”§ Otimizando prompt...
ğŸ”„ Roteando prompt...

============================================================
ğŸ“¤ PROMPT OTIMIZADO E ROTEADO:
============================================================
<instructions>
Explique machine learning de forma simples para iniciantes
</instructions>

<thinking>
Vou analisar cuidadosamente esta solicitaÃ§Ã£o e fornecer uma resposta detalhada e Ãºtil.
</thinking>

Por favor, processe esta solicitaÃ§Ã£o aplicando seu melhor raciocÃ­nio e conhecimento.

============================================================
â„¹ï¸  InformaÃ§Ãµes do roteamento:
   - LLM de destino: claude
   - Template usado: claude_template
   - Timestamp: 2025-08-30 11:52:15
```

## ğŸ§© Componentes Principais

### 1. PromptOptimizer (`chains/prompt_optimizer.py`)

ResponsÃ¡vel por otimizar prompts baseado no LLM de destino:

- **OtimizaÃ§Ãµes Gerais**: Remove espaÃ§os extras, normaliza formataÃ§Ã£o
- **OtimizaÃ§Ãµes EspecÃ­ficas**:
  - **Claude**: Estruturas XML, thinking tags
  - **OpenAI**: Prompts diretos, role context
  - **Cursor**: Contexto de programaÃ§Ã£o
  - **Universal**: FormataÃ§Ã£o compatÃ­vel com todos

### 2. LLMRouter (`chains/llm_router.py`)

Gerencia o roteamento inteligente:

- **DetecÃ§Ã£o AutomÃ¡tica**: Analisa conteÃºdo para escolher melhor LLM
- **Templates**: Aplica templates especÃ­ficos
- **Metadados**: Gera informaÃ§Ãµes sobre complexidade e linguagem

### 3. Settings (`config/settings.py`)

ConfiguraÃ§Ã£o centralizada:

- Carregamento de variÃ¡veis de ambiente
- ConfiguraÃ§Ãµes especÃ­ficas por LLM
- ValidaÃ§Ã£o de configuraÃ§Ãµes

### 4. Templates (`templates/`)

Templates otimizados para cada LLM:

- **claude_template.txt**: Estrutura XML, thinking tags
- **openai_template.txt**: System/User format, instruÃ§Ãµes claras
- **cursor_template.txt**: Foco em desenvolvimento
- **universal_template.txt**: CompatÃ­vel com qualquer LLM

## ğŸ“Š Roadmap de Desenvolvimento

### âœ… Fase 1: MVP (ConcluÃ­da)
- [x] Estrutura base do projeto
- [x] Sistema de otimizaÃ§Ã£o de prompts
- [x] Roteamento inteligente
- [x] Templates para diferentes LLMs
- [x] Sistema de logging
- [x] Interface de linha de comando

### ğŸš§ Fase 2: Multi-Output (Em Desenvolvimento)
- [ ] MÃºltiplos formatos de saÃ­da (JSON, Markdown, Plain Text)
- [ ] ComparaÃ§Ã£o de respostas entre LLMs
- [ ] Metrics de performance
- [ ] Cache de prompts otimizados

### ğŸ”„ Fase 3: Envio Direto (Planejado)
- [ ] IntegraÃ§Ã£o com API Anthropic (Claude)
- [ ] IntegraÃ§Ã£o com API OpenAI
- [ ] IntegraÃ§Ã£o com Cursor (quando disponÃ­vel)
- [ ] Retry automÃ¡tico e error handling
- [ ] Rate limiting inteligente

### ğŸŒ Fase 4: Interface Web (Futuro)
- [ ] Interface web intuitiva
- [ ] Dashboard de analytics
- [ ] HistÃ³rico de prompts
- [ ] Compartilhamento de templates
- [ ] API REST para integraÃ§Ã£o

## ğŸ”§ Desenvolvimento

### Estrutura de Classes Principais

```python
# Otimizador de prompts
optimizer = PromptOptimizer(settings)
optimized_prompt = optimizer.optimize("seu prompt", target_llm="claude")

# Roteador de LLMs  
router = LLMRouter(settings)
result = router.route_prompt(optimized_prompt, target="auto")

# Cliente de API (placeholder)
client = APIClient(settings)
response = await client.send_prompt(prompt, "claude")
```

### Adicionando Novos LLMs

1. **Adicione configuraÃ§Ãµes** em `config/settings.py`
2. **Crie template** em `templates/novo_llm_template.txt`
3. **Implemente otimizaÃ§Ãµes** em `chains/prompt_optimizer.py`
4. **Adicione roteamento** em `chains/llm_router.py`

### Executando Testes

```bash
# Quando implementado
pytest tests/ -v
```

## ğŸ“ Logs e Debugging

O sistema gera logs automÃ¡ticos em `logs/prompt_router_YYYYMMDD.log`:

```
2025-08-30 11:52:15 | prompt_router | INFO | PromptOptimizer inicializado  
2025-08-30 11:52:15 | prompt_router | INFO | LLMRouter inicializado
2025-08-30 11:52:16 | prompt_router | INFO | Iniciando otimizaÃ§Ã£o para claude
2025-08-30 11:52:16 | prompt_router | DEBUG | Aplicando otimizaÃ§Ãµes para Claude
```

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ™‹â€â™‚ï¸ Suporte

Para dÃºvidas, problemas ou sugestÃµes:

- Abra uma issue no repositÃ³rio
- Consulte os logs em `logs/` para debugging
- Verifique a configuraÃ§Ã£o do `.env`

---

**Desenvolvido com â¤ï¸ para otimizar sua experiÃªncia com LLMs**

*Ãšltima atualizaÃ§Ã£o: 30/08/2025 - v1.0.0 MVP*
